{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Traffic Sign Recognition** \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./writeup_material/exploratory.png \"Visualization\"\n",
    "[image2]: ./writeup_material/before.png \"Before Grayscaling\"\n",
    "[image3]: ./writeup_material/after.png \"After\"\n",
    "[image4]: ./writeup_material/predict_01.png \"Traffic Sign 1\"\n",
    "[image5]: ./writeup_material/predict_02.png \"Traffic Sign 2\"\n",
    "[image6]: ./writeup_material/predict_03.png \"Traffic Sign 3\"\n",
    "[image7]:./writeup_material/predict_04.png \"Traffic Sign 4\"\n",
    "[image8]: ./writeup_material/predict_05.png \"Traffic Sign 5\"\n",
    "[image9]: ./writeup_material/top_5.JPG \"Top 5\"\n",
    "[image10]: ./writeup_material/feature_map.JPG \"Feature Map\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Set Summary & Exploration\n",
    "\n",
    "#### 1. A basic summary of the data set\n",
    "\n",
    "I used the numpy library to calculate summary statistics of the traffic\n",
    "signs data set:\n",
    "\n",
    "* The size of training set is ?\n",
    "    34799\n",
    "* The size of the validation set is ?\n",
    "    4410\n",
    "* The size of test set is ?\n",
    "    12630\n",
    "* The shape of a traffic sign image is ?\n",
    "    (32,32,3)\n",
    "* The number of unique classes/labels in the data set is ?\n",
    "    43\n",
    "\n",
    "#### 2. An exploratory visualization of the dataset.\n",
    "\n",
    "Here is an exploratory visualization of the data set. It is a bar chart showing how the data distributed. It's clear that the data set are unbalanced. \n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "### Design and Test a Model Architecture\n",
    "\n",
    "\n",
    "\n",
    "#### 1. Preprocessed the image data\n",
    "\n",
    "As a first step, I decided to convert the images to grayscale because using color channels won't improve things a lot.\n",
    "\n",
    "Then, I devide the data with 255 to normalize the image data in order to make searching faster.\n",
    "\n",
    "I also apply histogram equalization to extract more feature from the image.\n",
    "\n",
    "Here is an example of a traffic sign image before and after pre processing.\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Model architecture\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x1 grayscale image   \t\t\t\t\t\t\t| \n",
    "| Convolution1 5x5x6     \t| 1x1 stride, valid padding, outputs 28x28x6 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 14x14x6 \t\t\t\t|\n",
    "| Convolution2 5x5x16\t    | 1x1 stride, valid padding, outputs 10x10x16  \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 5x5x16 \t\t\t\t|\n",
    "| Fully connected1\t\t| inputs 400, outputs 120\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Droupout\t\t\t\t\t|\t\t\tkeep probility 50%\t\t|\n",
    "| Fully connected2\t\t| inputs 120, outputs 84\t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected3\t\t| inputs 84, outputs 43\t|\n",
    "| Softmax\t\t\t\t|       softmax cross entropy with logits\t\t\t|\n",
    "\n",
    "\n",
    "\n",
    "#### 3. Modele Training\n",
    "\n",
    "To train the model, I used training dataset with TensorFlow AdamOptimizer and learning rate set to 0.001. I use batch size 256 and 100 epochs,however, It normally stops improving after ~60 epochs and achieve ~96% accuracy on the validdation data set.\n",
    "\n",
    "\n",
    "\n",
    "#### 4. Discuss\n",
    "\n",
    "At first, I try to use the same architecture from LeNet lab, but the maximum accuracy I can achieve is around 87%. Then I tried to normalize the data to make the searching fater. After implement the histogram equalization, 92% of accuracy was achieved. The last measure I took is add dropout to the fully connected layer to avoid overfitting and I tune the final model with a lower learning rate. Then it is able to achieve 96 % of accuracy in the validation data set and 94.2%  in the test data set.\n",
    "\n",
    "\n",
    "My final model results were:\n",
    "* validation set accuracy of 96.3%\n",
    "* test set accuracy of 94.2%\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "### Test a Model on New Images\n",
    "\n",
    "#### 1. New Image\n",
    "\n",
    "Here are five German traffic signs that I found on the web:\n",
    "\n",
    "![alt text][image4] ![alt text][image5] ![alt text][image6] \n",
    "![alt text][image7] ![alt text][image8]\n",
    "\n",
    "The first image might be difficult to classify because there is some dirt on it.\n",
    "\n",
    "#### 2.Model Prediction\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Image\t\t\t        |     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| No entry      \t\t| No entry   \t\t\t\t\t\t\t\t\t| \n",
    "| Speed limit(20km/h)     \t\t\t| Speed limit(20km/h) \t\t\t\t\t|\n",
    "| Children crpssing\t\t\t\t\t| Children crpssing\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Yield\t      \t\t| Yield\t\t\t\t\t \t\t\t\t|\n",
    "| Keep left\t\t\t| Keep left      \t\t\t\t\t\t\t|\n",
    "\n",
    "\n",
    "The model was able to correctly guess 5 of the 5 traffic signs, which gives an accuracy of 100%. This is excellent result, but maybe it's just because the new image are not challenging enough.\n",
    "\n",
    "#### 3. Softmax Probability\n",
    "\n",
    "The code for making predictions on my final model is located in the 14th cell of the Ipython notebook.\n",
    "\n",
    "\n",
    " ![alt text][image9]\n",
    "\n",
    "\n",
    "For the first image, the model is relatively sure that this is a stop sign (probability of 49%), and the image does contain a no entry sign. The top five soft max probabilities were\n",
    "\n",
    "\n",
    "\n",
    "For the second image, the model is not so sure about different speed limit. It seems the model is reletively not good at number regonization than graph regonization. \n",
    "\n",
    "\n",
    "### (Optional) Visualizing the Neural Network (See Step 4 of the Ipython notebook for more details)\n",
    "\n",
    "#### 1. Feature maps\n",
    "The visualization of conv1 layer is shown here, which contains 6 5x5 filters. As expect, the first layer is able to detect low level pixel patterns, like the \"-\" sign in the no entry traffi sign.\n",
    "\n",
    " ![alt text][image10]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
